<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <style>
    body {
        background-color: #404040;
        background-color: white;
        padding: 100px;
        width: 800px;
        margin: auto;
        text-align: left;
        font-weight: 300;
        font-family: 'Open Sans', sans-serif;
        color: #121212;
        line-height: 1.6;
    }
    h1, h2, h3, h4 {
        font-family: 'Source Sans Pro', sans-serif;
    }
    kbd {
        color: #121212;
    }
    blockquote {
        color: #888;
        border: 2px solid #333;
        padding: 10px;
        background-color: #ccc;
    }

    table.custom-tbl {
        border: 1px solid;
    }

    table.custom-tbl th {
        border: 1px solid;
        background-color: rgb(99, 209, 209);
    }

    table.custom-tbl td {
        border: 1px solid;
        background-color: #f1e686a8;
    }
  </style>

  <!-- <title>CS 184 Mesh Editor</title> -->
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <!-- Not using below due to lacking bold fontfaces -->
  <!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro|Source+Sans+Pro:400,700" rel="stylesheet"> -->
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono|Roboto+Slab|Roboto:300,400,500,700" rel="stylesheet" />

  <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>  
</head>

<body>

    <h1 align="middle">CS 184 Final Project</h1>
    <h1 align="middle">FluidDIT(Maybe a better name?)</h1>
    <h3 align="middle">Charles Cai, Congrong Xu, Franklin Zhang, Yunqi Li</h3>
    <p align="middle">Authurs are sorted in alphabetical order</p>

  

    <br><br>

    <div>
        <h2 align="middle">Overview</h2>
        <p>
            We plan to design a novel Diffusion Transformers model for predicting predicting nonlinear fluid fields.
            The model is expected to generate predictions for the flow state under specified initial conditions.
        </p>
    </div>

    <h2 align="middle">Problem Description</h2>

    <p>
        Computational Fluid Dynamics (CFD) is a field of study that uses numerical methods and algorithms to solve and analyze problems that involve fluid flows.
        Methods like Smoothed Particle Hydrodynamics (SPH) and Lattice Boltzmann Method (LBM) are commonly used to simulate fluid flows.
        However, these methods are computationally expensive and require large amounts of Computation resources.
        On the other hand, some previous works have shown that deep learning models can be used to predict fluid flows with high accuracy and efficiency.
        In this project, we aim to design a novel Diffusion Transformers model for predicting nonlinear fluid fields and try to improve the efficiency and accuracy of deep learning based fluid flow prediction.
    </p>

    <h2 align="middle">Goals and Deliverables</h2>
    <p>
        Our goals are as follows:
        <ul>
            <li>Reproduce the results of the baseline models e.g. FluidDIff, PINN(Phisics Informed Neural Networks), etc..
            <li>Build a Diffusion Transformers model for predicting fluid fields and train the model on a dataset of 2D fluid flow simulations</li>
            <li>Evaluate the performance of the model on the test set using MAE(Mean Absolute Error) and RMSE(Root Mean Squared Error)</li>
            <li>Optimize the model to improve the performance</li>
            <li>Compare the performance of the model with other baseline models</li>
        </ul>
        Our deliverables include:
        <ul>
            <li>A Ground Truth visualization of the fluid flow on the test set</li>
            <li>A visualization of the predictions of the baseline model on the test set</li>
            <li>A visualization of the predictions of the Diffusion Transformers model on the test set</li>
    </p>

    <h2 align="middle">Schedule</h2>

    <table class="custom-tbl">
        <tr>
            <th>Week&emsp;</th>
            <th>Primary Goals</th>
            <th>Secondary Goals</th>
        </tr>
        <tr>
            <td>Week 1</td>
            <td>Build the dataset for training and reproduce the results of FluidDiff baseline models</td>
            <td>Start to build the Diffusion Transformers model and the Training Pipeline</td>
        </tr>
        <tr>
            <td>Week 2</td>
            <td>Finish building the Diffusion Transformers model and the Training Pipeline</td>
            <td>Build the evaluation pipeline and prepare the test set for evaluation</td>
        </tr>
        <tr>
            <td>Week 3</td>
            <td>Train and optimize the Diffusion Transformers model</td>
            <td>Reproduce the results of other baseline models and evaluate the performance of the Diffusion Transformers model</td>
        </tr>
        <tr>
            <td>Week 4</td>
            <td>Optimize the model and generate the final results</td>
            <td>Prepare the final report and presentation</td>
        </tr>
    </table>

    <h2 align="middle">Resources</h2>
    <p>
        Paper resources:
        <ul>
            <li> <a href="https://dev.neurips.cc/virtual/2023/74855#details">Gefan Yang and Stefan Sommer. A denoising diffusion model for fluid field prediction. arXiv preprint502 arXiv:2301.11661, 2023.50312</a></li>
            <li> <a href="https://arxiv.org/abs/2105.09506">Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics-499 informed neural networks (pinns) for fluid mechanics: A review, 2021.</a> </li>
            <li> <a href="https://www.wpeebles.com/DiT">William Peebles. DiT: Diffusion Transformers for Scalable Fluid Flow Prediction. arXiv preprint arXiv:2303.498</a></li>
        </ul>
        Computing resources:
        <ul>
            <li>Google Colab</li>
            <li>Self-owned GPU</li>
            <li>UC Berkeley GPU Cluster</li>
        </ul>

</body>
</html>
